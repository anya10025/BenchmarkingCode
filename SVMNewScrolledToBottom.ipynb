{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f6e47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance: Resistance\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "X shape: (98, 197)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/anyakhurana/Documents/Rpo_analysis_project/rpoABC_variation_rifampicin_resistance.csv\")\n",
    "\n",
    "# Target encoding\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "# One-hot encode features\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "\n",
    "# Stratified CV for fairness\n",
    "cv10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Class balance:\", y.value_counts(normalize=True))\n",
    "print(\"X shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5ffad0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "19592ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "46ff1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SVC(probability=True, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2d77366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3baa59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # safe for sparse one-hot\n",
    "    ('clf', SVC(probability=True, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0013356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fdb6dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # safe for sparse one-hot\n",
    "    ('clf', SVC(probability=True, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d97b456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resistance\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "(array([0, 1]), array([50, 48]))\n",
      "(array([0, 1]), array([52, 46]))\n",
      "(array([0, 1]), array([51, 47]))\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))  # Class balance\n",
    "for model in [svm_best, log_best, xgb_best]:\n",
    "    print(np.unique(model.predict(X), return_counts=True))  # Predicting both classes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "388cf450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'NC_000962.3:3877464-3878507+287',\n",
      "       'NC_000962.3:3877464-3878507+689', 'NC_000962.3:759807-763325+36',\n",
      "       'NC_000962.3:759807-763325+97', 'NC_000962.3:759807-763325+132',\n",
      "       'NC_000962.3:759807-763325+509', 'NC_000962.3:759807-763325+606',\n",
      "       'NC_000962.3:759807-763325+673', 'NC_000962.3:759807-763325+696',\n",
      "       'NC_000962.3:759807-763325+801', 'NC_000962.3:759807-763325+857',\n",
      "       'NC_000962.3:759807-763325+1133', 'NC_000962.3:759807-763325+1289',\n",
      "       'NC_000962.3:759807-763325+1303', 'NC_000962.3:759807-763325+1304',\n",
      "       'NC_000962.3:759807-763325+1325', 'NC_000962.3:759807-763325+1333',\n",
      "       'NC_000962.3:759807-763325+1334', 'NC_000962.3:759807-763325+1335',\n",
      "       'NC_000962.3:759807-763325+1349', 'NC_000962.3:759807-763325+1471',\n",
      "       'NC_000962.3:759807-763325+2014', 'NC_000962.3:759807-763325+2479',\n",
      "       'NC_000962.3:759807-763325+2728', 'NC_000962.3:759807-763325+3189',\n",
      "       'NC_000962.3:759807-763325+3225', 'NC_000962.3:763370-767320+321',\n",
      "       'NC_000962.3:763370-767320+1204', 'NC_000962.3:763370-767320+1297',\n",
      "       'NC_000962.3:763370-767320+1355', 'NC_000962.3:763370-767320+1380',\n",
      "       'NC_000962.3:763370-767320+1432', 'NC_000962.3:763370-767320+1448',\n",
      "       'NC_000962.3:763370-767320+1449', 'NC_000962.3:763370-767320+1451',\n",
      "       'NC_000962.3:763370-767320+1453', 'NC_000962.3:763370-767320+1471',\n",
      "       'NC_000962.3:763370-767320+1519', 'NC_000962.3:763370-767320+1549',\n",
      "       'NC_000962.3:763370-767320+1776', 'NC_000962.3:763370-767320+2093',\n",
      "       'NC_000962.3:763370-767320+2201', 'NC_000962.3:763370-767320+2249',\n",
      "       'NC_000962.3:763370-767320+2290', 'NC_000962.3:763370-767320+2498',\n",
      "       'NC_000962.3:763370-767320+2726', 'NC_000962.3:763370-767320+2843',\n",
      "       'NC_000962.3:763370-767320+2873', 'NC_000962.3:763370-767320+3116',\n",
      "       'NC_000962.3:763370-767320+3119', 'NC_000962.3:763370-767320+3525',\n",
      "       'NC_000962.3:763370-767320+3606', 'Sample', 'ID', 'Resistance'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0 NC_000962.3:3877464-3878507+287 NC_000962.3:3877464-3878507+689  \\\n",
      "0           0                               T                               T   \n",
      "1           1                               C                               T   \n",
      "2           2                               T                               T   \n",
      "3           3                               T                               T   \n",
      "4           4                               T                               T   \n",
      "\n",
      "  NC_000962.3:759807-763325+36 NC_000962.3:759807-763325+97  \\\n",
      "0                            T                            G   \n",
      "1                            T                            G   \n",
      "2                            T                            G   \n",
      "3                            T                            G   \n",
      "4                            T                            G   \n",
      "\n",
      "  NC_000962.3:759807-763325+132 NC_000962.3:759807-763325+509  \\\n",
      "0                             T                             T   \n",
      "1                             T                             T   \n",
      "2                             T                             T   \n",
      "3                             T                             T   \n",
      "4                             T                             T   \n",
      "\n",
      "  NC_000962.3:759807-763325+606 NC_000962.3:759807-763325+673  \\\n",
      "0                             C                             C   \n",
      "1                             C                             C   \n",
      "2                             C                             C   \n",
      "3                             C                             C   \n",
      "4                             C                             C   \n",
      "\n",
      "  NC_000962.3:759807-763325+696  ... NC_000962.3:763370-767320+2726  \\\n",
      "0                             C  ...                              C   \n",
      "1                             C  ...                              C   \n",
      "2                             C  ...                              C   \n",
      "3                             C  ...                              C   \n",
      "4                             C  ...                              C   \n",
      "\n",
      "  NC_000962.3:763370-767320+2843 NC_000962.3:763370-767320+2873  \\\n",
      "0                              A                              C   \n",
      "1                              A                              C   \n",
      "2                              A                              C   \n",
      "3                              A                              C   \n",
      "4                              A                              C   \n",
      "\n",
      "  NC_000962.3:763370-767320+3116 NC_000962.3:763370-767320+3119  \\\n",
      "0                              T                              C   \n",
      "1                              T                              C   \n",
      "2                              T                              C   \n",
      "3                              T                              C   \n",
      "4                              T                              C   \n",
      "\n",
      "  NC_000962.3:763370-767320+3525 NC_000962.3:763370-767320+3606      Sample  \\\n",
      "0                              T                              C  ERR4810461   \n",
      "1                              T                              C  ERR4810467   \n",
      "2                              T                              C  ERR4810478   \n",
      "3                              T                              C  ERR4810486   \n",
      "4                              T                              C  ERR4810491   \n",
      "\n",
      "           ID Resistance  \n",
      "0  ERR4810461          R  \n",
      "1  ERR4810467          R  \n",
      "2  ERR4810478          R  \n",
      "3  ERR4810486          R  \n",
      "4  ERR4810491          S  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"/Users/anyakhurana/Documents/Rpo_analysis_project/rpoABC_variation_rifampicin_resistance.csv\")\n",
    "\n",
    "# Print the first few rows and the column names\n",
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9b320cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(class_weight='balanced', probability=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3943b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,     \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f534de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (78, 197)\n",
      "Testing data shape: (20, 197)\n",
      "\n",
      "First 5 rows of training data:\n",
      "    Unnamed: 0  NC_000962.3:3877464-3878507+287_C  \\\n",
      "19          19                              False   \n",
      "67          67                              False   \n",
      "72          72                              False   \n",
      "74          74                              False   \n",
      "0            0                              False   \n",
      "\n",
      "    NC_000962.3:3877464-3878507+287_T  NC_000962.3:3877464-3878507+689_C  \\\n",
      "19                               True                              False   \n",
      "67                               True                              False   \n",
      "72                               True                              False   \n",
      "74                               True                              False   \n",
      "0                                True                              False   \n",
      "\n",
      "    NC_000962.3:3877464-3878507+689_T  NC_000962.3:759807-763325+36_C  \\\n",
      "19                               True                           False   \n",
      "67                               True                           False   \n",
      "72                               True                           False   \n",
      "74                               True                           False   \n",
      "0                                True                           False   \n",
      "\n",
      "    NC_000962.3:759807-763325+36_T  NC_000962.3:759807-763325+97_C  \\\n",
      "19                            True                           False   \n",
      "67                            True                           False   \n",
      "72                            True                           False   \n",
      "74                            True                           False   \n",
      "0                             True                           False   \n",
      "\n",
      "    NC_000962.3:759807-763325+97_G  NC_000962.3:759807-763325+132_A  ...  \\\n",
      "19                            True                            False  ...   \n",
      "67                            True                            False  ...   \n",
      "72                            True                            False  ...   \n",
      "74                            True                            False  ...   \n",
      "0                             True                            False  ...   \n",
      "\n",
      "    Sample_ERR4811047  Sample_ERR4811048  Sample_ERR4811049  \\\n",
      "19              False              False              False   \n",
      "67              False              False              False   \n",
      "72              False              False              False   \n",
      "74              False              False              False   \n",
      "0               False              False              False   \n",
      "\n",
      "    Sample_ERR4811053  Sample_ERR4811054  Sample_ERR4811065  \\\n",
      "19              False              False              False   \n",
      "67              False              False              False   \n",
      "72              False              False              False   \n",
      "74              False              False              False   \n",
      "0               False              False              False   \n",
      "\n",
      "    Sample_ERR4811066  Sample_ERR4811109  Sample_ERR4811135  Sample_ERR4811141  \n",
      "19              False              False              False              False  \n",
      "67              False              False              False              False  \n",
      "72              False              False              False              False  \n",
      "74              False              False              False              False  \n",
      "0               False              False              False              False  \n",
      "\n",
      "[5 rows x 197 columns]\n",
      "\n",
      "First 5 rows of testing data:\n",
      "    Unnamed: 0  NC_000962.3:3877464-3878507+287_C  \\\n",
      "73          73                              False   \n",
      "66          66                              False   \n",
      "55          55                              False   \n",
      "1            1                               True   \n",
      "11          11                              False   \n",
      "\n",
      "    NC_000962.3:3877464-3878507+287_T  NC_000962.3:3877464-3878507+689_C  \\\n",
      "73                               True                              False   \n",
      "66                               True                              False   \n",
      "55                               True                              False   \n",
      "1                               False                              False   \n",
      "11                               True                              False   \n",
      "\n",
      "    NC_000962.3:3877464-3878507+689_T  NC_000962.3:759807-763325+36_C  \\\n",
      "73                               True                           False   \n",
      "66                               True                           False   \n",
      "55                               True                           False   \n",
      "1                                True                           False   \n",
      "11                               True                           False   \n",
      "\n",
      "    NC_000962.3:759807-763325+36_T  NC_000962.3:759807-763325+97_C  \\\n",
      "73                            True                           False   \n",
      "66                            True                           False   \n",
      "55                            True                           False   \n",
      "1                             True                           False   \n",
      "11                            True                           False   \n",
      "\n",
      "    NC_000962.3:759807-763325+97_G  NC_000962.3:759807-763325+132_A  ...  \\\n",
      "73                            True                            False  ...   \n",
      "66                            True                            False  ...   \n",
      "55                            True                            False  ...   \n",
      "1                             True                            False  ...   \n",
      "11                            True                            False  ...   \n",
      "\n",
      "    Sample_ERR4811047  Sample_ERR4811048  Sample_ERR4811049  \\\n",
      "73              False              False              False   \n",
      "66              False              False              False   \n",
      "55              False              False              False   \n",
      "1               False              False              False   \n",
      "11              False              False              False   \n",
      "\n",
      "    Sample_ERR4811053  Sample_ERR4811054  Sample_ERR4811065  \\\n",
      "73              False              False              False   \n",
      "66              False              False              False   \n",
      "55              False              False              False   \n",
      "1               False              False              False   \n",
      "11              False              False              False   \n",
      "\n",
      "    Sample_ERR4811066  Sample_ERR4811109  Sample_ERR4811135  Sample_ERR4811141  \n",
      "73              False              False              False              False  \n",
      "66              False              False              False              False  \n",
      "55              False              False              False              False  \n",
      "1               False              False              False              False  \n",
      "11              False              False              False              False  \n",
      "\n",
      "[5 rows x 197 columns]\n",
      "\n",
      "Training labels distribution:\n",
      "Resistance\n",
      "0    39\n",
      "1    39\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing labels distribution:\n",
      "Resistance\n",
      "1    10\n",
      "0    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of testing data:\")\n",
    "print(X_test.head())\n",
    "\n",
    "print(\"\\nTraining labels distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nTesting labels distribution:\")\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "af29acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 60 is smaller than n_iter=100. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (XGB): {'kernel': 'rbf', 'gamma': 'auto', 'C': 100}\n",
      "Best Score (XGB): 0.9589473684210527\n",
      "Best Estimator (XGB): SVC(C=100, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "#  Prepare Data\n",
    "# =========================\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "y = df['Resistance']\n",
    "# show categorical features (if needed)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "# show target labels to numeric: 'S' -> 0, 'R' -> 1\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "\n",
    "# we need to do Hyperparameter Tuning\n",
    "# =========================\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "\n",
    "# Define the cross-validation \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#load the random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model correctly\n",
    "random_search.fit(X_encoded, y_encoded)\n",
    "print(\"Best Parameters (XGB):\", random_search.best_params_)\n",
    "print(\"Best Score (XGB):\", random_search.best_score_)\n",
    "print(\"Best Estimator (XGB):\", random_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b7273335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 60 is smaller than n_iter=100. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (XGB): {'kernel': 'rbf', 'gamma': 'auto', 'C': 100}\n",
      "Best Score (XGB): 0.9800000000000001\n",
      "Best Estimator (XGB): SVC(C=100, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "#  Prepare Data\n",
    "# =========================\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "y = df['Resistance']\n",
    "# show categorical features (if needed)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "# show target labels to numeric: 'S' -> 0, 'R' -> 1\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "\n",
    "# we need to do Hyperparameter Tuning\n",
    "# =========================\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "\n",
    "# Define the cross-validation \n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#load the random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model correctly\n",
    "random_search.fit(X_encoded, y_encoded)\n",
    "print(\"Best Parameters (XGB):\", random_search.best_params_)\n",
    "print(\"Best Score (XGB):\", random_search.best_score_)\n",
    "print(\"Best Estimator (XGB):\", random_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad34d2ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 907, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 943, in partial_fit\n    X = validate_data(\n        self,\n    ...<4 lines>...\n        reset=first_call,\n    )\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 2954, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'T'\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 907, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 943, in partial_fit\n    X = validate_data(\n        self,\n    ...<4 lines>...\n        reset=first_call,\n    )\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 2954, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'C'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m svm_params = {\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__C\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__kernel\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrbf\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__gamma\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mscale\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m }\n\u001b[32m     11\u001b[39m svm_search = RandomizedSearchCV(svm_pipe, svm_params, n_iter=\u001b[32m10\u001b[39m, cv=cv10, n_jobs=-\u001b[32m1\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43msvm_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSVM best score:\u001b[39m\u001b[33m\"\u001b[39m, svm_search.best_score_)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# --- Logistic Regression ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 907, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 943, in partial_fit\n    X = validate_data(\n        self,\n    ...<4 lines>...\n        reset=first_call,\n    )\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 2954, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'T'\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 907, in fit\n    return self.partial_fit(X, y, sample_weight)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_data.py\", line 943, in partial_fit\n    X = validate_data(\n        self,\n    ...<4 lines>...\n        reset=first_call,\n    )\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 2954, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2168, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'C'\n"
     ]
    }
   ],
   "source": [
    "# --- SVM ---\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SVC(probability=True, random_state=42))\n",
    "])\n",
    "svm_params = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__kernel': ['linear', 'rbf'],\n",
    "    'clf__gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_search = RandomizedSearchCV(svm_pipe, svm_params, n_iter=10, cv=cv10, n_jobs=-1, random_state=42)\n",
    "svm_search.fit(X, y)\n",
    "print(\"SVM best score:\", svm_search.best_score_)\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "log_params = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "log_search = RandomizedSearchCV(log_pipe, log_params, n_iter=10, cv=cv10, n_jobs=-1, random_state=42)\n",
    "log_search.fit(X, y)\n",
    "print(\"Logistic best score:\", log_search.best_score_)\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "rf_search = RandomizedSearchCV(rf, rf_params, n_iter=10, cv=cv10, n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X, y)\n",
    "print(\"Random Forest best score:\", rf_search.best_score_)\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=10, cv=cv10, n_jobs=-1, random_state=42)\n",
    "xgb_search.fit(X, y)\n",
    "print(\"XGB best score:\", xgb_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f976ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:21:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "ROC-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Hold-out test set check\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "best_model = xgb_search.best_estimator_  # replace with model you want to test\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5fc25e",
   "metadata": {},
   "source": [
    "## End of XG-Boost and SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed962bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1})  \n",
    "\n",
    "\n",
    "X_encoded = pd.get_dummies(X).fillna(0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449db90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Best Params (LogReg): {'penalty': 'l1', 'C': 10}\n",
      "Best CV Accuracy (tuning on train): 0.8821428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "# Train/test split (so we tune only on training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear',   # supports L1/L2 for binary\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100],\n",
    "    'penalty': ['l1', 'l2']   \n",
    "}\n",
    "\n",
    "# 10-fold cross \n",
    "cv_tune = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,                 # try up to 20 combos\n",
    "    scoring='accuracy',        # use 'roc_auc' if you prefer\n",
    "    cv=cv_tune,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params (LogReg):\", random_search.best_params_)\n",
    "print(\"Best CV Accuracy (tuning on train):\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785535a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV Accuracies (train only): [1.         0.875      0.75       0.875      0.875      1.\n",
      " 0.875      1.         0.71428571 0.85714286]\n",
      "Mean CV Accuracy: 0.8821428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "best_logreg = random_search.best_estimator_\n",
    "\n",
    "cv_10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_logreg, X_train, y_train, cv=cv_10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"10-Fold CV Accuracies (train only):\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc7641",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      3\u001b[39m log_pipe = Pipeline([\n\u001b[32m      4\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m, StandardScaler(with_mean=\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[32m      5\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, LogisticRegression(solver=\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m42\u001b[39m))\n\u001b[32m      6\u001b[39m ])\n\u001b[32m      8\u001b[39m log_space = {\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__C\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m100\u001b[39m],\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__penalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m log_search = RandomizedSearchCV(log_pipe, log_space, n_iter=\u001b[32m20\u001b[39m, cv=\u001b[43mcv10\u001b[49m, n_jobs=-\u001b[32m1\u001b[39m, random_state=\u001b[32m42\u001b[39m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m     14\u001b[39m log_search.fit(X, y)\n\u001b[32m     15\u001b[39m log_best = log_search.best_estimator_\n",
      "\u001b[31mNameError\u001b[39m: name 'cv10' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "log_space = {\n",
    "    'clf__C': [0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1','l2']\n",
    "}\n",
    "\n",
    "log_search = RandomizedSearchCV(log_pipe, log_space, n_iter=20, cv=cv10, n_jobs=-1, random_state=42, verbose=1)\n",
    "log_search.fit(X, y)\n",
    "log_best = log_search.best_estimator_\n",
    "log_scores = cross_val_score(log_best, X, y, cv=cv10, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression  Test Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.91      1.00      0.95        10\n",
      "           R       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "ROC-AUC (Test): 0.9800000000000001\n",
      "Average Precision (Test): 0.9833333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit best model on training data\n",
    "best_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "proba_test = best_logreg.predict_proba(X_test)[:, 1]\n",
    "pred_test = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Logistic Regression  Test Performance ===\")\n",
    "print(classification_report(y_test, pred_test, target_names=[\"S\", \"R\"], zero_division=0))\n",
    "print(\"ROC-AUC (Test):\", roc_auc_score(y_test, proba_test))\n",
    "print(\"Average Precision (Test):\", average_precision_score(y_test, proba_test))\n",
    "\n",
    "# Compare prediction probability distributions by true class (test set)\n",
    "plt.figure()\n",
    "plt.hist(proba_test[y_test == 0], bins=10, alpha=0.6, label='True S (0)')\n",
    "plt.hist(proba_test[y_test == 1], bins=10, alpha=0.6, label='True R (1)')\n",
    "plt.xlabel(\"Predicted Probability of R\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Logistic Regression  Test Probabilities by Class\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e8899",
   "metadata": {},
   "source": [
    "## Logistic regression - split into test and train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b29a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83139dc7",
   "metadata": {},
   "source": [
    "## Logistic Regression Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb28dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Parameters: {'clf__penalty': 'l2', 'clf__C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "log_param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "log_search = RandomizedSearchCV(\n",
    "    estimator=log_pipe,\n",
    "    param_distributions=log_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_search.fit(X_train, y_train)\n",
    "print(\"Best Logistic Regression Parameters:\", log_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f501b2",
   "metadata": {},
   "source": [
    "## Logistic Regression - 10 fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b000366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n",
      "Test Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_best = log_search.best_estimator_\n",
    "log_scores = cross_val_score(log_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"Logistic Regression CV Accuracies:\", log_scores)\n",
    "print(\"Average Accuracy:\", np.mean(log_scores))\n",
    "\n",
    "# Test set performance\n",
    "y_pred = log_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "# Define the model\n",
    "log_reg = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716cb448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best Params: {'penalty': 'l1', 'C': 10}\n",
      "Best CV Accuracy: 0.8988888888888888\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Cross-validation strategy for tuning\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_strategy,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_encoded, y_encoded)\n",
    "\n",
    "print(\"Best Params:\", random_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Parameters: {'clf__penalty': 'l2', 'clf__C': 0.01}\n",
      "Logistic Regression CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n",
      "Test Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Logistic Regression: Step 1 - Data Split ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Encode features/target\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 2 - Hyperparameter Tuning ---\n",
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "log_param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "log_search = RandomizedSearchCV(\n",
    "    estimator=log_pipe,\n",
    "    param_distributions=log_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression Parameters:\", log_search.best_params_)\n",
    "\n",
    "# --- Step 3 - 10-fold Cross-Validation with Best Model ---\n",
    "log_best = log_search.best_estimator_\n",
    "log_scores = cross_val_score(log_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"Logistic Regression CV Accuracies:\", log_scores)\n",
    "print(\"Average Accuracy:\", np.mean(log_scores))\n",
    "\n",
    "# Final test performance\n",
    "y_pred = log_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5ccce",
   "metadata": {},
   "source": [
    "## SVM - split into test and train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac785e46",
   "metadata": {},
   "source": [
    "# SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdc53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Parameters: {'clf__kernel': 'linear', 'clf__gamma': 'scale', 'clf__C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SVC(probability=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "svm_param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__kernel': ['linear', 'rbf'],\n",
    "    'clf__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "svm_search = RandomizedSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_distributions=svm_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_search.fit(X_train, y_train)\n",
    "print(\"Best SVM Parameters:\", svm_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a98b8b",
   "metadata": {},
   "source": [
    "##. SVM 10 fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f97d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n",
      "Test Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = svm_search.best_estimator_\n",
    "svm_scores = cross_val_score(svm_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"SVM CV Accuracies:\", svm_scores)\n",
    "print(\"Average Accuracy:\", np.mean(svm_scores))\n",
    "\n",
    "# Test set performance\n",
    "y_pred = svm_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcd7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Parameters: {'clf__kernel': 'linear', 'clf__gamma': 'scale', 'clf__C': 0.01}\n",
      "SVM CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n",
      "Test Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- SVM: Step 1 - Data Split ---\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 2 - Hyperparameter Tuning ---\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SVC(probability=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "svm_param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__kernel': ['linear', 'rbf'],\n",
    "    'clf__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "svm_search = RandomizedSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_distributions=svm_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVM Parameters:\", svm_search.best_params_)\n",
    "\n",
    "# --- Step 3 - 10-fold Cross-Validation with Best Model ---\n",
    "svm_best = svm_search.best_estimator_\n",
    "svm_scores = cross_val_score(svm_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"SVM CV Accuracies:\", svm_scores)\n",
    "print(\"Average Accuracy:\", np.mean(svm_scores))\n",
    "\n",
    "# Final test performance\n",
    "y_pred = svm_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7980e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1276c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters: {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "print(\"Best XGBoost Parameters:\", xgb_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7278afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CV Accuracies: [0.9        1.         1.         0.9        1.         0.9\n",
      " 1.         1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9588888888888889\n",
      "Test Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_best = xgb_search.best_estimator_\n",
    "xgb_scores = cross_val_score(xgb_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"XGBoost CV Accuracies:\", xgb_scores)\n",
    "print(\"Average Accuracy:\", np.mean(xgb_scores))\n",
    "\n",
    "# Test set performance\n",
    "y_pred = xgb_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19391a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters: {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:27:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CV Accuracies: [0.9        1.         1.         0.9        1.         0.9\n",
      " 1.         1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9588888888888889\n",
      "Test Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost: Step 1 - Data Split ---\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 2 - Hyperparameter Tuning ---\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost Parameters:\", xgb_search.best_params_)\n",
    "\n",
    "# --- Step 3 - 10-fold Cross-Validation with Best Model ---\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "xgb_scores = cross_val_score(xgb_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"XGBoost CV Accuracies:\", xgb_scores)\n",
    "print(\"Average Accuracy:\", np.mean(xgb_scores))\n",
    "\n",
    "# Final test performance\n",
    "y_pred = xgb_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfe5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "Best parameters found (Logistic Regression): {'clf__penalty': 'l2', 'clf__C': 100}\n",
      "Best cross-validation accuracy: 0.9089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data\n",
    "X_encoded = pd.get_dummies(df.drop(columns=['ID', 'Resistance']))\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1})\n",
    "\n",
    "# Pipeline for scaling + logistic regression\n",
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_log = {\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "random_search_log = RandomizedSearchCV(\n",
    "    estimator=log_pipe,\n",
    "    param_distributions=param_grid_log,\n",
    "    n_iter=20,\n",
    "    cv=10,  # 10-fold CV\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_log.fit(X_encoded, y)\n",
    "\n",
    "print(\"Best parameters found (Logistic Regression):\", random_search_log.best_params_)\n",
    "print(f\"Best cross-validation accuracy: {random_search_log.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2763b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ..clf__C=0.01, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .....clf__C=0.01, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.01, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=0.01, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=0.1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=0.1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=0.1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=0.1, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=1, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ........clf__C=1, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=1, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .........clf__C=1, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=10, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .......clf__C=10, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .....clf__C=10, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ...clf__C=100, clf__gamma=scale, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ........clf__C=10, clf__gamma=auto, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ......clf__C=100, clf__gamma=scale, clf__kernel=rbf; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ....clf__C=100, clf__gamma=auto, clf__kernel=linear; total time=   0.1s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......clf__C=100, clf__gamma=auto, clf__kernel=rbf; total time=   0.0s\n",
      "Best parameters found (SVM): {'clf__kernel': 'linear', 'clf__gamma': 'scale', 'clf__C': 0.01}\n",
      "Best cross-validation accuracy: 0.9089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Pipeline for scaling + SVM\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SVC(probability=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_svm = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__kernel': ['linear', 'rbf'],\n",
    "    'clf__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "random_search_svm = RandomizedSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_distributions=param_grid_svm,\n",
    "    n_iter=20,\n",
    "    cv=10,  # 10-fold CV\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_svm.fit(X_encoded, y)\n",
    "\n",
    "print(\"Best parameters found (SVM):\", random_search_svm.best_params_)\n",
    "print(f\"Best cross-validation accuracy: {random_search_svm.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6a427cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 200 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/sklearn.py\", line 1641, in fit\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['R' 'S']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     10\u001b[39m param_grid_xgb = {\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m50\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m300\u001b[39m],\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m9\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcolsample_bytree\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.8\u001b[39m, \u001b[32m1.0\u001b[39m]\n\u001b[32m     16\u001b[39m }\n\u001b[32m     18\u001b[39m random_search_xgb = RandomizedSearchCV(\n\u001b[32m     19\u001b[39m     estimator=xgb,\n\u001b[32m     20\u001b[39m     param_distributions=param_grid_xgb,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mrandom_search_xgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters found (XGBoost):\u001b[39m\u001b[33m\"\u001b[39m, random_search_xgb.best_params_)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest cross-validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_search_xgb.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 200 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/sklearn.py\", line 1641, in fit\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['R' 'S']\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid_xgb,\n",
    "    n_iter=20,\n",
    "    cv=10,  # 10-fold CV\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_xgb.fit(X_encoded, y)\n",
    "\n",
    "print(\"Best parameters found (XGBoost):\", random_search_xgb.best_params_)\n",
    "print(f\"Best cross-validation accuracy: {random_search_xgb.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bb227",
   "metadata": {},
   "source": [
    "## logistic regression - split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9ab2dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data\n",
    "X_encoded = pd.get_dummies(df.drop(columns=['ID', 'Resistance']))\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299410ec",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9c7b03e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 12 candidates, totalling 180 fits\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ......................clf__C=0.001, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .......................clf__C=0.01, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ..........................clf__C=1, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END .........................clf__C=10, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l1; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.1s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "[CV] END ........................clf__C=100, clf__penalty=l2; total time=   0.0s\n",
      "Best parameters: {'clf__penalty': 'l2', 'clf__C': 0.001}\n",
      "Best CV accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_log = {\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "random_search_log = RandomizedSearchCV(\n",
    "    estimator=log_pipe,\n",
    "    param_distributions=param_grid_log,\n",
    "    n_iter=20,\n",
    "    cv=15,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_log.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", random_search_log.best_params_)\n",
    "print(f\"Best CV accuracy: {random_search_log.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867f76b",
   "metadata": {},
   "source": [
    "## 10 fold cross logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "95a5a581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "log_best = random_search_log.best_estimator_\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_log = cross_val_score(log_best, X_encoded, y, cv=cv)\n",
    "\n",
    "print(\"10-Fold CV Accuracies:\", scores_log)\n",
    "print(\"Average Accuracy:\", np.mean(scores_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca89157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Logistic Regression Model\n",
    "log_model = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluation\n",
    "y_pred = log_model.predict(X_test)\n",
    "log_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", log_acc)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1eb6cb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(scores_log, bins=5, edgecolor='black')\n",
    "plt.title(\"Logistic Regression - CV Score Distribution\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c802c",
   "metadata": {},
   "source": [
    "# Logistic Regression # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382900c",
   "metadata": {},
   "source": [
    "# split into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1aae136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1578f8",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "592d6cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Parameters: {'clf__penalty': 'l2', 'clf__C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "log_param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "log_search = RandomizedSearchCV(\n",
    "    estimator=log_pipe,\n",
    "    param_distributions=log_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_search.fit(X_train, y_train)\n",
    "print(\"Best Logistic Regression Parameters:\", log_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd709b",
   "metadata": {},
   "source": [
    "## 1 fold cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c312b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n",
      "Test Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_best = log_search.best_estimator_\n",
    "log_scores = cross_val_score(log_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"Logistic Regression CV Accuracies:\", log_scores)\n",
    "print(\"Average Accuracy:\", np.mean(log_scores))\n",
    "\n",
    "# Test set performance\n",
    "y_pred = log_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b6b9a",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ccac1",
   "metadata": {},
   "source": [
    "# training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4772d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d38c4",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9e14f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Parameters: {'clf__kernel': 'linear', 'clf__gamma': 'scale', 'clf__C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('clf', SVC(probability=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "svm_param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__kernel': ['linear', 'rbf'],\n",
    "    'clf__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "svm_search = RandomizedSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_distributions=svm_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_search.fit(X_train, y_train)\n",
    "print(\"Best SVM Parameters:\", svm_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd53f6",
   "metadata": {},
   "source": [
    "# 10 fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5df06567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV Accuracies: [0.9        0.8        1.         0.8        0.8        1.\n",
      " 0.9        1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9088888888888889\n",
      "Test Accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = svm_search.best_estimator_\n",
    "svm_scores = cross_val_score(svm_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"SVM CV Accuracies:\", svm_scores)\n",
    "print(\"Average Accuracy:\", np.mean(svm_scores))\n",
    "\n",
    "# Test set performance\n",
    "y_pred = svm_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e866a",
   "metadata": {},
   "source": [
    "# Xg-Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44973776",
   "metadata": {},
   "source": [
    "# split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "586b8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = df.drop(columns=['ID', 'Resistance'])\n",
    "X = pd.get_dummies(X, drop_first=False)\n",
    "y = df['Resistance'].map({'S': 0, 'R': 1}).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f17de7",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0becfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters: {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "print(\"Best XGBoost Parameters:\", xgb_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4779eff",
   "metadata": {},
   "source": [
    "# 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc0ef00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [15:52:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CV Accuracies: [0.9        1.         1.         0.9        1.         0.9\n",
      " 1.         1.         0.88888889 1.        ]\n",
      "Average Accuracy: 0.9588888888888889\n",
      "Test Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_best = xgb_search.best_estimator_\n",
    "xgb_scores = cross_val_score(xgb_best, X, y, cv=cv_strategy, n_jobs=-1)\n",
    "\n",
    "print(\"XGBoost CV Accuracies:\", xgb_scores)\n",
    "print(\"Average Accuracy:\", np.mean(xgb_scores))\n",
    "\n",
    "# Test set performance\n",
    "y_pred = xgb_best.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ead33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "310025f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8925d489",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
